"""Tests for ChromaDB storage implementation.

This module tests the ChromaStore implementation with mock data to verify
correct storage, retrieval, and metadata handling.
"""

import logging

import pytest

from config import settings
from models import DocumentChunk, RetrievalResult
from storage.chroma_store import ChromaStore

logger = logging.getLogger(__name__)


@pytest.fixture
async def chroma_store() -> ChromaStore:
    """Create and initialize ChromaStore for testing.

    Returns:
        Initialized ChromaStore instance
    """
    config = settings.get_storage_config("chroma")
    # Use a test collection name to avoid interfering with production data
    config["collection_name"] = "test_petroleum_docs"

    # Use context manager for proper cleanup
    async with ChromaStore(config) as store:
        # Clear any existing data
        await store.clear()

        yield store

        # Cleanup after test
        try:
            await store.clear()
        except Exception as e:
            logger.warning(f"Cleanup failed: {e}")


@pytest.fixture
def mock_chunks() -> list[DocumentChunk]:
    """Create mock document chunks for testing.

    Returns:
        List of mock DocumentChunk objects
    """
    return [
        DocumentChunk(
            chunk_id="chunk_001",
            document_id="doc_001",
            content="Petroleum reservoir engineering involves the study of fluid flow in porous media.",
            element_ids=["elem_001"],
            metadata={"source": "textbook"},
            chunk_index=0,
            start_page=1,
            end_page=1,
            token_count=15,
            parent_section="Introduction",
        ),
        DocumentChunk(
            chunk_id="chunk_002",
            document_id="doc_001",
            content="Enhanced oil recovery (EOR) techniques include thermal, chemical, and gas injection methods.",
            element_ids=["elem_002"],
            metadata={"source": "textbook"},
            chunk_index=1,
            start_page=1,
            end_page=2,
            token_count=16,
            parent_section="Chapter 1",
        ),
        DocumentChunk(
            chunk_id="chunk_003",
            document_id="doc_002",
            content="Drilling operations require careful consideration of mud weight and formation pressure.",
            element_ids=["elem_003"],
            metadata={"source": "manual"},
            chunk_index=0,
            start_page=5,
            end_page=5,
            token_count=14,
            parent_section="Operations",
        ),
        DocumentChunk(
            chunk_id="chunk_004",
            document_id="doc_002",
            content="Well completion techniques vary based on reservoir characteristics and production goals.",
            element_ids=["elem_004"],
            metadata={"source": "manual"},
            chunk_index=1,
            start_page=6,
            end_page=6,
            token_count=13,
            parent_section="Completion",
        ),
        DocumentChunk(
            chunk_id="chunk_005",
            document_id="doc_003",
            content="Production optimization involves maximizing recovery while minimizing operational costs.",
            element_ids=["elem_005"],
            metadata={"source": "paper"},
            chunk_index=0,
            start_page=10,
            end_page=10,
            token_count=12,
            parent_section="Optimization",
        ),
    ]


@pytest.fixture
def mock_embeddings() -> list[list[float]]:
    """Create mock embeddings for testing.

    Returns:
        List of mock embedding vectors
    """
    # Create simple mock embeddings (dimensionality = 384 for testing)
    # In real usage, these would be generated by an embedding model
    import random

    random.seed(42)  # Ensure reproducibility

    return [[random.random() for _ in range(384)] for _ in range(5)]


@pytest.mark.asyncio
async def test_chroma_store_initialization(chroma_store: ChromaStore) -> None:
    """Test ChromaStore initialization.

    Args:
        chroma_store: ChromaStore fixture
    """
    assert chroma_store._initialized is True
    assert chroma_store.collection is not None
    assert chroma_store.client is not None

    # Test health check
    health = await chroma_store.health_check()
    assert health is True

    logger.info("ChromaStore initialization test passed")


@pytest.mark.asyncio
async def test_store_and_retrieve_chunks(
    chroma_store: ChromaStore,
    mock_chunks: list[DocumentChunk],
    mock_embeddings: list[list[float]],
) -> None:
    """Test storing and retrieving chunks.

    Args:
        chroma_store: ChromaStore fixture
        mock_chunks: Mock chunks fixture
        mock_embeddings: Mock embeddings fixture
    """
    # Store chunks
    await chroma_store.store_chunks(mock_chunks, mock_embeddings)

    # Verify storage
    count = chroma_store.collection.count()
    assert count == 5, f"Expected 5 chunks, got {count}"

    # Retrieve using first embedding as query
    query_embedding = mock_embeddings[0]
    results = await chroma_store.retrieve(
        query="test query",
        query_embedding=query_embedding,
        top_k=3,
    )

    # Verify results
    assert len(results) > 0, "No results returned"
    assert len(results) <= 3, f"Expected max 3 results, got {len(results)}"

    # Check result format
    first_result = results[0]
    assert isinstance(first_result, RetrievalResult)
    assert first_result.chunk_id in [c.chunk_id for c in mock_chunks]
    assert first_result.document_id in ["doc_001", "doc_002", "doc_003"]
    assert 0.0 <= first_result.score <= 1.0
    assert first_result.rank >= 1
    assert first_result.retrieval_method == "vector"

    # Verify results are ranked by score
    scores = [r.score for r in results]
    assert scores == sorted(scores, reverse=True), "Results not sorted by score"

    logger.info("Store and retrieve test passed")


@pytest.mark.asyncio
async def test_retrieve_with_filters(
    chroma_store: ChromaStore,
    mock_chunks: list[DocumentChunk],
    mock_embeddings: list[list[float]],
) -> None:
    """Test retrieval with metadata filters.

    Args:
        chroma_store: ChromaStore fixture
        mock_chunks: Mock chunks fixture
        mock_embeddings: Mock embeddings fixture
    """
    # Store chunks
    await chroma_store.store_chunks(mock_chunks, mock_embeddings)

    # Retrieve with document_id filter
    query_embedding = mock_embeddings[0]
    results = await chroma_store.retrieve(
        query="test query",
        query_embedding=query_embedding,
        top_k=10,
        filters={"document_id": "doc_001"},
    )

    # Verify all results are from doc_001
    assert len(results) > 0, "No results returned with filter"
    for result in results:
        assert result.document_id == "doc_001", f"Unexpected document_id: {result.document_id}"

    logger.info("Retrieve with filters test passed")


@pytest.mark.asyncio
async def test_chunk_metadata_preservation(
    chroma_store: ChromaStore,
    mock_chunks: list[DocumentChunk],
    mock_embeddings: list[list[float]],
) -> None:
    """Test that chunk metadata is preserved during storage and retrieval.

    Args:
        chroma_store: ChromaStore fixture
        mock_chunks: Mock chunks fixture
        mock_embeddings: Mock embeddings fixture
    """
    # Store chunks
    await chroma_store.store_chunks(mock_chunks, mock_embeddings)

    # Retrieve all
    query_embedding = mock_embeddings[0]
    results = await chroma_store.retrieve(
        query="test query",
        query_embedding=query_embedding,
        top_k=10,
    )

    # Check metadata preservation
    assert len(results) > 0, "No results returned"

    first_result = results[0]
    metadata = first_result.metadata

    # Verify expected metadata fields
    assert "document_id" in metadata
    assert "chunk_index" in metadata
    assert "start_page" in metadata or "end_page" in metadata

    logger.info("Metadata preservation test passed")


@pytest.mark.asyncio
async def test_clear_collection(
    chroma_store: ChromaStore,
    mock_chunks: list[DocumentChunk],
    mock_embeddings: list[list[float]],
) -> None:
    """Test clearing the collection.

    Args:
        chroma_store: ChromaStore fixture
        mock_chunks: Mock chunks fixture
        mock_embeddings: Mock embeddings fixture
    """
    # Store chunks
    await chroma_store.store_chunks(mock_chunks, mock_embeddings)

    # Verify storage
    count_before = chroma_store.collection.count()
    assert count_before == 5, f"Expected 5 chunks before clear, got {count_before}"

    # Clear collection
    await chroma_store.clear()

    # Verify collection is empty
    count_after = chroma_store.collection.count()
    assert count_after == 0, f"Expected 0 chunks after clear, got {count_after}"

    logger.info("Clear collection test passed")


@pytest.mark.asyncio
async def test_validation_errors(chroma_store: ChromaStore) -> None:
    """Test validation errors for invalid inputs.

    Args:
        chroma_store: ChromaStore fixture
    """
    # Test empty chunks
    with pytest.raises(ValueError, match="Cannot store empty chunks"):
        await chroma_store.store_chunks([], [])

    # Test length mismatch
    chunk = DocumentChunk(
        chunk_id="test_001",
        document_id="doc_001",
        content="Test content",
    )
    with pytest.raises(ValueError, match="length mismatch"):
        await chroma_store.store_chunks([chunk], [[0.1, 0.2], [0.3, 0.4]])

    logger.info("Validation errors test passed")


@pytest.mark.asyncio
async def test_min_score_threshold(
    chroma_store: ChromaStore,
    mock_chunks: list[DocumentChunk],
    mock_embeddings: list[list[float]],
) -> None:
    """Test minimum score threshold filtering.

    Args:
        chroma_store: ChromaStore fixture
        mock_chunks: Mock chunks fixture
        mock_embeddings: Mock embeddings fixture
    """
    # Store chunks
    await chroma_store.store_chunks(mock_chunks, mock_embeddings)

    # Set high minimum score threshold
    chroma_store.config["min_score"] = 0.95

    # Retrieve with high threshold - should get fewer results
    query_embedding = mock_embeddings[2]  # Use different embedding
    results = await chroma_store.retrieve(
        query="test query",
        query_embedding=query_embedding,
        top_k=10,
    )

    # All returned results should meet threshold
    for result in results:
        assert result.score >= 0.95, f"Result score {result.score} below threshold"

    logger.info("Min score threshold test passed")


@pytest.mark.asyncio
async def test_large_batch_storage(chroma_store: ChromaStore) -> None:
    """Test storing large batches of chunks.

    Args:
        chroma_store: ChromaStore fixture
    """
    import random

    random.seed(42)

    # Create 1500 mock chunks (will test batch processing)
    large_chunks = [
        DocumentChunk(
            chunk_id=f"chunk_{i:04d}",
            document_id=f"doc_{i // 100:03d}",
            content=f"Content for chunk {i} with various petroleum engineering terms.",
            chunk_index=i % 100,
            start_page=(i // 10) + 1,
            end_page=(i // 10) + 2,
        )
        for i in range(1500)
    ]

    # Create embeddings
    large_embeddings = [[random.random() for _ in range(384)] for _ in range(1500)]

    # Store large batch
    await chroma_store.store_chunks(large_chunks, large_embeddings)

    # Verify storage
    count = chroma_store.collection.count()
    assert count == 1500, f"Expected 1500 chunks, got {count}"

    logger.info("Large batch storage test passed")


@pytest.mark.asyncio
async def test_context_manager() -> None:
    """Test using ChromaStore as async context manager."""
    config = settings.get_storage_config("chroma")
    config["collection_name"] = "test_context_manager"

    # Use context manager
    async with ChromaStore(config) as store:
        # Store should be initialized
        assert store._initialized is True
        assert store.collection is not None

        # Should be able to check health
        health = await store.health_check()
        assert health is True

    # After exiting context, resources should be cleaned up
    assert store._initialized is False
    assert store.client is None

    logger.info("Context manager test passed")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
